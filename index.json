[{"authors":["admin"],"categories":null,"content":"I am driven to deliver innovative, data based, solutions which provide impact and value. Not one to shy away from a challenge, I completed a PhD in 2017 which focused on improving flood forecasting skill at Monash University.\nCareer highlights for me have involved working in interdisciplinary teams to deliver adaptation pathways to guide a city to transition to a water sensitive city and the delivery of guidelines to improve flood forecasting skill using remote sensing data.\nOutside of work you can find me training in Brazilian Jiu Jitsu (BJJ). It is a martial art that is often described as human chess. I enjoy the challenges, exercise, and culture associated with BJJ.\nView my CV\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://AshjWright88.github.io/author/ashley-wright/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ashley-wright/","section":"authors","summary":"I am driven to deliver innovative, data based, solutions which provide impact and value. Not one to shy away from a challenge, I completed a PhD in 2017 which focused on improving flood forecasting skill at Monash University.","tags":null,"title":"Ashley Wright","type":"authors"},{"authors":null,"categories":null,"content":"The ongoing COVID-19 pandemic has caused widespread disruptions to everyday life and the global economy. Many existing forecast models no longer provide the same accuracy they once did. Consequently, being able to account for the change in conditions would prove quite valuable.\nHigh resolution electricity consumption data is a potential proxy for economic activity. The nexus between electricity consumption and GDP is a widely debated topic. A McKinsey quarterly article suggests that decoupling of GDP and energy growth occurs as economies advance.\nJournal articles which demonstrate a link between reduced electricity consumption as a result of COVID-19 restrictions are starting to appear.\nIn my blog posts; A, B, C, and D I explore Australian electricity consumption data for observable patterns that can be attributed to restrictions brought on by COVID-19. This blog post will demonstrate how I detected a change in Victorian electricity consumption which can be attributed to COVID-19 restrictions.\nThe rest of this post outlines the:\n methodology used, key results \u0026amp; discussion, and conclusions.  Methodology To deliver meaningful results in a short time I committed to posting weekly blog posts on LinkedIn. These blog posts enabled me to produce results straight away, scale my project accordingly, and gain valuable feedback from interested data scientists. The blog posts covered:\n Exploratory Data Analysis, tracking model development, model drift, and a way to attribute forecast errors to COVID-19 restrictions.  I will now provide an overview of the key results and discussions to be found in my blog posts.\nResults \u0026amp; Discussion Victoria has had the most severe restrictions in Australia. Consequently, Victorian electricity consumption is most likely to be impacted by COVID-19 restrictions. Before developing a model, it is essential that the data and its potential errors are understood.\n  Key takeaways from decomposing the Victorian electricity consumption data are:\n There is a slight downward trend which may be attributable to the adoption of renewable energy and efficiency measures. There is a clear seasonality with peak consumption occurring throughout winter. Errors are most obvious near the start of the year.  Using one step ahead forecasts, the Holt-Winters\u0026rsquo; triple exponential smoother is used as a benchmark to track value gained from adding causal variables as inputs to MLP and LSTM neural networks are explored.\n  Key takeaways from tracking model development are:\n Both LSTM and MLP neural networks outperform the benchmark. The MLP significantly improves when the day of the week is included. The LSTM significantly improves when maximum and minimum temperatures are included.  I now explore how errors can be reduced by retraining the MLP neural network to prevent model drift.\n  Key takeaways from tracking model drift are:\n By tracking model drift average reductions in forecast errors 8.15% can be observed. A reduction of errors is not guaranteed. As seen in blog C forecast errors do not drift significantly from the test data set.  After developing a robust model that performs well in a number of states it is not difficult to scale the solution to a 30-minute one step ahead forecast model.\nTo avoid electricity consumption data during COVID-19 restrictions leaking into our model and preventing us from detecting a change attributable to COVID-19 restrictions, the following model does not use past electricity consumption data as an input variable.\nBy setting a binary vector to 1 from the start of COVID-19 restrictions in Australia we can determine if our MLP neural network can learn a different pattern for electricity consumption throughout COVID-19 restrictions and provide improved forecasts.\n  Key takeaways from tracking model drift before and after COVID-19 restrictions are:\n The MLP NN which accounts for COVID-19 restrictions drifts significantly less than its counterpart. Errors for both models are comparable before COVID-19 restrictions were put in places. We can confidently say that a change in electricity consumption data has been detected for Victoria.  Conclusions By developing a MLP ANN that uses causal variables to predict step ahead electricity consumption in Victoria, I was able to detect a change in Victorian electricity consumption data which is attributable to COVID-19 restrictions.\nThroughout this blog post, I have demonstrated the value of tracking model performance, developing scalable experiments, and obtaining consistent feedback.\nPlease find my GitHub repository here and current resume here.\n","date":1602979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602979200,"objectID":"7f95562a92edf5ba9491a9d8317bcdd0","permalink":"https://AshjWright88.github.io/post/energy-consumption-pandemic-insights/","publishdate":"2020-10-18T00:00:00Z","relpermalink":"/post/energy-consumption-pandemic-insights/","section":"post","summary":"The ongoing COVID-19 pandemic has caused widespread disruptions to everyday life and the global economy. Many existing forecast models no longer provide the same accuracy they once did. Consequently, being able to account for the change in conditions would prove quite valuable.","tags":null,"title":"Neural Network Driven Insights into Electricity Consumption Data During COVID-19","type":"post"},{"authors":null,"categories":null,"content":"There are a number of situations in which past data of the observation we are making forecasts for is not available. Possible reasons include time lags between data collection and data availability, and the time taken to quality control data.\nConsequently, there is value to be gained by developing predictive models which do not rely on the availability of recent observations of the variable that we are trying to forecast. Further, by developing a causal MLP neural network we are able to attribute changes in electricity consumption to COVID-19 restrictions.\nUsing 30 minute electricity consumption for Victoria this blog will:\n Develop a feature based causal model used to predict 1 step ahead electricity consumption. Develop a model which uses a binary flag to indicate the start of COVID-19 restrictions in Victoria. Compare model forecast densities with the observed electricity consumption. Use model drift to demonstrate when performance improvements occur. Show that by including a binary flag which indicates the start of COVID-19 restrictions, test errors can be reduced by 5.08%  Using a feature based causal MLP ANN to forecast electricity consumption If we are able to account for all the key variables which drive electricity consumption then we would not need to incorporate past electricity consumption into our causal model. The MLP used to make day one step ahead electricity consumption forecasts uses 6 neurons and is trained with dropout of 6%. The variables included are the past 7 days values for average, minimum and maximum temperature, solar radiation, time of the day, day of the week, public holiday flag, and Christmas holiday flag. Even though similar results were found using the past 24 hours values, values for the past 7 days were used to account for any potential hangover effects from holidays, hot or cold weather spells, or weekends.\n  Key takeaway messages from the 30-minute causal model for Victoria include:\n Errors appear to be increasing in the test period. High and low electricity consumption forecasts tend to respectively be smaller and larger than observations. General consumption trend and seasonality are modelled quite well.  Accounting for COVID-19 restrictions in electricity consumption forecasts To account for possible behavioural changes due to COVID-19 restrictions in Victoria we now introduce a binary flag that starts on March 23 2020 and persists to the current day.\n  Key takeaway messages from including a flag to represent COVID-19 restrictions include:\n Errors no longer increase as much in the test period. There does not appear to be a significant difference between the two models\u0026rsquo; forecast capability. Further analysis is required to detect a change in forecast capability.  Comparing model forecast densities Visualising the time series forecasts and resulting residuals is one way to detect a change in forecast behavior. The absence of an obvious distinction between the two models does not indicate that there is no change. An alternative method to compare the model results is to analyse the density plots for the observed and modelled electricity consumption for the training and test period.\n  Key takeaway messages from analysing density plots include:\n Both models are able represent the observed density in training relatively well. There is a greater difference between the observed and modelled densities in the test period. Including a flag for COVID-19 restrictions produces a density which is slightly more representative of the observed density for the test period.  Tracking model drift to detect changes in electricity consumption resulting from COVID-19 restrictions We have observed a small difference between the density plots in the test period and now move on to check if the two models relative errors are different throughout the COVID-19 restrictions period.\n  Key takeaway messages from tracking model drift are:\n By including a flag which accounts for COVID-19 restrictions our causal model drifts noticeably less. It is possible that the base model even starts to drift in the training period. The base model performs slightly better in the training period.  Throughout these blog posts I have used the same neural network and random seed. It is possible that results would differ if an ensemble or different seed was used. I attempted to account for this by training for a large number of epochs and using model checkpoints to select the model which had the best validation period performance.\nReductions in forecast errors by accounting for COVID-19 restrictions A noticeable drift in relative errors that can be attributed to COVID-19 restrictions in Victoria was observed. We can now quantify these results.\n  Key takeaway messages using a binary flag to represent COVID-19 restrictions include:\n There is a reduction in errors of 5.08% While both models have similar performance it is likely that including the binary flag for COVID-19 restrictions will make the model more robust for future predictions. There is less difference between test and training MAPE for the model which includes a binary flag for COVID-19. This suggests the model was less prone to over-fitting.  Summary This blog post has demonstrated that model forecast errors can be attributed to the change in behaviour that has resulted from COVID-19 restrictions. Furthermore, by including a binary flag which accounts for COVID-19 restrictions our model is more robust and less prone to drift.\n","date":1602892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602979200,"objectID":"f2ddc6c521e736d9b4561d4ea30619da","permalink":"https://AshjWright88.github.io/post/energy-consumption-pandemic-part-d/","publishdate":"2020-10-17T00:00:00Z","relpermalink":"/post/energy-consumption-pandemic-part-d/","section":"post","summary":"There are a number of situations in which past data of the observation we are making forecasts for is not available. Possible reasons include time lags between data collection and data availability, and the time taken to quality control data.","tags":null,"title":"Attributing Forecast Errors to COVID-19 Restrictions","type":"post"},{"authors":null,"categories":null,"content":"To improve forecasting capability during uncertain times it is necessary to both understand and address model drift. The hypothesis I aim to test is that electricity consumption forecasts will be more prone to errors in states that have seen more severe and prolonged restrictions as a result of COVID-19.\nUsing daily electricity consumption for Vic, NSW, Tas, SA, and QLD this blog will demonstrate:\n What model drift is. The importance of using train, development, and test splits. The estimated operational performance of day ahead forecasts using MLP ANN\u0026rsquo;s. Model drift in an operational setting. That tracking model performance and regularly re-training models, errors can be reduced by an average of 8.15%.  What is model drift? Model drift is the degradation of forecasting capability over time. One method to tackle this problem is to re-train forecasting models. By scaling the errors for each forecasting model to 100 we can track how each model drifts.\n  Key takeaway messages from tracking model development include:\n Drift occurs slowly. There is a small increase in errors as the model progressively makes predictions on development and test data. Relative errors fluctuate around 100 during the training period. Model drift can be used to indicate how our model is likely to perform further into the future.  At this point it is essential to ask \u0026ldquo;what causes model drift?\u0026quot;\nThe cause of model drift and importance of train, dev, test splits. Model drift results from using a forecasting model that was developed using one data set to make forecasts for a data set with different statistical properties. This commonly occurs when we make forecasts in uncertain or unprecedented times.\nTo make reliable forecasts it is necessary to develop models using training, development, and test sets.\n The training set is used to update model parameters and assess performance when the model has seen the data. The training and development sets are used to tune hyper-parameters. 3.The test set is used to assess performance on a data set the model has not seen.  Using a scaled density plot we can visualise the cause of model drift and importance of train, dev, test splits.\n  Key takeaway messages from reviewing the scaled density plots for Victoria include:\n The density function for each data set is significantly different. If only a train and test set are used then there is no way to assess performance on an unknown data set. We are likely to see model drift in the Dev and Test sets.  Estimating operational performance of MLP ANN\u0026rsquo;s to predict electricity consumption. The train and development sets were used tune hyper-parameters. A 6-neuron layer and Dropout of 8% were used to avoid over-fitting. Using the test set we can now estimate model performance in an operational setting.\n   Low mean absolute percentage error indicates better model performance\nKey takeaway messages from reviewing model performance in each state include:\n Model performance using the test set is indicative of operational performance. Models perform best using the training data set. States that consume more electricity have lower mean absolute percentage errors, this is a result of the error metric used.  Model drift in an operational setting. Prior to making operational forecasts it is now wise to take advantage of all the data available and re-train the model.\nUsing 2020 as a forecast year we can now test the initial hypothesis that states which have seen more severe and prolonged restrictions as a result of COVID-19 will be more prone to errors.\n  The key takeaway messages from reviewing model performance are:\n Victorian electricity consumption forecasts tend to drift more than others. Is this a result of tighter restrictions? Errors tend to have a seasonal component; this indicates further improvements can be made to the model and that we cannot assume a jump in errors is caused by tighter restrictions. More pronounced changes may be observable at the 30 min timescale.  Reduction in operational forecast errors by tracking model performance and re-training models. As the scale of the model grows both the resources required and the time taken to re-train models need to be weighed against the end-user’s tolerance for error.\nUsing data up until the start of September 2020 we can now re-train our models and estimate the value gained by re-training the models instead of leaving them to drift.\n  The key takeaway messages from reviewing model performance for each state in September 2020 include:\n By tracking model drift and re-training our models, reductions in operational forecast errors of 8.15% can be realised. A reduction of errors is not guaranteed. Operational performance is similar to that estimated earlier.  Summary I have provided an overview of one way to track and account for model drift. Following this procedure allows end-users to track operational model performance and schedule re-training when a desired threshold is met.\nWe tracked model drift using 2020 electricity consumption data. It is not entirely clear if the increase in model errors can be attributed to restrictions put in place to combat COVID-19. Developing forecast models at greater resolution may provide more insights.\n","date":1602460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602979200,"objectID":"5f4e33b07113c480535d1d0da1207faa","permalink":"https://AshjWright88.github.io/post/energy-consumption-pandemic-part-c/","publishdate":"2020-10-12T00:00:00Z","relpermalink":"/post/energy-consumption-pandemic-part-c/","section":"post","summary":"To improve forecasting capability during uncertain times it is necessary to both understand and address model drift. The hypothesis I aim to test is that electricity consumption forecasts will be more prone to errors in states that have seen more severe and prolonged restrictions as a result of COVID-19.","tags":null,"title":"Accounting for Model Drift","type":"post"},{"authors":null,"categories":null,"content":"Using the daily Victorian electricity consumption as an example, this blog will outline procedures to develop a forecasting model. To enable scheduling of energy supply for the next day I develop one day ahead forecasts. In my next post I will use this model to outline procedures to improve forecasting capability during uncertain times.\nWhen developing a model, it is easy to get carried away and build a fancy, shiny model which resembles a formula One car. If we are wanting to go off road, then this model/car is next to useless. It is imperative to develop a fit for purpose model and track modeling improvements.\nThis blog will outline how I have:\n Tracked model development to ensure time is spent on measurable and valuable model improvements. Cleaned and explored the data. Developed a benchmark forecasting model. Developed a LSTM recurrent neural network to forecast electricity consumption. Developed a MLP artificial neural network to forecast electricity consumption.  Tracking Model Development Using the mean absolute percentage error, I demonstrate below one way that improvement can be tracked as model features are added and model complexity grows.\n  Model performance is greatest when the mean absolute percentage error reaches zero.\nKey takeaway messages from tracking model development include:\n Both the MLP and LSTM outperform the benchmark model. The MLP significantly improves when the day of the week is included. The LSTM significantly improves when maximum and minimum temperatures are included.  At this point it is essential to ask \u0026ldquo;will the end user benefit from further model development\u0026rdquo;?\nData Cleaning and Exploratory Data Analysis I now outline the process used to develop these models.\nModels are only ever as good as the data they are built on and the understanding of the key variables which cause a change in the observations.\nThis dataset was checked for:\n Missing data points. Outliers. General inconsistencies.  Now we can explore the data and look for hints that will help us construct an appropriate model.\n  Key takeaway messages from reviewing the decomposed electricity consumption for Victoria include:\n From 2014 to 2019 there is a slight downward trend in electricity consumption, this may be a result of electricity efficiency measures or an uptake in solar panels. There is a clear yearly seasonal component that is likely to be a result of seasonal fluctuations in temperature and subsequent heating and cooling consumption. The residuals show that errors tend to peak at the beginning of the year.  Benchmark Model Upon reviewing Statistical and Machine Learning forecasting methods we can see that exponential smoothing models commonly outperform other statistical and machine learning models. Well suited to model seasonality and trend we use the Holt - Winters triple exponential smoother as our benchmark.\n  Key takeaway messages from reviewing the benchmark model:\n The benchmark model captures the annual seasonality. Residuals in training still show errors peaking at the start of the year. The residuals in development show a weekly pattern which is most due to lower electricity consumption on weekends.  Long Short-Term Memory Recurrent Neural Network The LSTM RNN is a popular choice for time series forecasting. This model learns from the past 7 days of electricity consumption, minimum, maximum, and average temperature, and solar radiation. It is assumed that we will have a good estimate of the next day\u0026rsquo;s weather.\n  The key takeaway messages from reviewing LSTM model performance are:\n The LSTM significantly out-performs the benchmark model capturing peak consumption much better. The residuals in training show that there is a pattern to the errors. These peaks are likely to be around holiday periods. The residuals in development still show a weekly pattern.  Multilayer Perceptron Artificial Neural Network Instead of perceiving electricity consumption as a time series model we can develop a causal model which forecasts electricity consumption as a function of the past 7 days for weather, day of the week and year, holiday period and trend. The MLP ANN is well suited to this task.\n  The key takeaway messages from reviewing MLP model performance are:\n Including weekends and holidays which account for behavioural changes commonly associated with changes to electricity consumption significantly improves performance. The model tends to under and over-predict peaks and troughs respectively. An alternate loss function may help this. Since behaviour is a key element to electricity consumption forecasting, we can expect electricity consumption during the pandemic to be more difficult to forecast.  Summary In this blog post I provided an overview of one way to develop a benchmark model and use it to track improvements made by other models. Following this procedure allows end users to follow to model development process and identify shortcomings and priorities. It is shown that the MLP which accounts for the day of the week and holidays significantly outperforms the LSTM and benchmark model.\nYou may have noticed that I did not test the model using Victorian electricity consumption data for 2019 onward. Preventing test data from being used in model development enables us to make more reliable forecasts. Next week I will outline procedures to improve forecasting capability during uncertain times.\n","date":1601856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602979200,"objectID":"066149478f8d61bc56b0499f8b34b504","permalink":"https://AshjWright88.github.io/post/energy-consumption-pandemic-part-b/","publishdate":"2020-10-05T00:00:00Z","relpermalink":"/post/energy-consumption-pandemic-part-b/","section":"post","summary":"Using the daily Victorian electricity consumption as an example, this blog will outline procedures to develop a forecasting model. To enable scheduling of energy supply for the next day I develop one day ahead forecasts.","tags":null,"title":"Developing Neural Networks to Forecast Electricity Consumption","type":"post"},{"authors":null,"categories":null,"content":"The COVID-19 pandemic has changed our understanding of uncertainty and what exactly normal is. We have seen economies free fall, toilet paper being hoarded, and unprecedented amounts of data made publicly available. To say that pivot has emerged as a buzzword is an understatement. How then should we decide which direction to pivot in? Let us see what we can learn from the data.\nThis weekly blog will deliver insights into:\n The observed changes in electricity consumption during the pandemic. What impact changed habits have on forecasting capability. The value to be gained.  As a starting point we will profile the typical weekday and weekend electricity consumption and reference price for Victorian\u0026rsquo;s during the current stage 4 restrictions. To gain further insight into the potential impact stage 4 restrictions have on electricity consumption and price, we will make comparisons for the same time period last year in Victoria and similarly New South Wales, a state which is not currently under stage 4 restrictions.\nVictorian Electricity consumption profiles during stage 4 restrictions Fluctuations in Electricity consumption are predominantly influenced by human behaviour and the consumption for heating and cooling. Typically, when comparing electricity consumption across years and seasons, consumption data is normalized by the weather. It is not pragmatic to normalise the 30 min electricity consumption data, made available through AEMO, by the daily temperature observations made available through the BoM. Consequently, we will compare electricity consumption data without factoring in heating and cooling requirements.\n  Key takeaway messages from reviewing Victorian electricity consumption data include:\n Our weekends are looking less regular. Midday consumption is flatter on weekends. Weekend electricity consumption shows more variation, particularly during stage 4 restrictions between 7 AM and 3PM.  New South Wales electricity consumption profiles during Victoria\u0026rsquo;s stage 4 restrictions Naturally, I was then curious to compare the Victorian electricity consumption profiles to those found in a state which does not currently have stage 4 restrictions in place. Let\u0026rsquo;s look at the neighbouring state of NSW.\n  Key takeaway messages from reviewing NSW electricity consumption data include:\n There are less changes in midday consumption on the weekends. Less restrictions in NSW may be associated with more consistency in electricity consumption. Aggregated electricity consumption across NSW and Victoria has not significantly changed. This was not expected. It is quite possible that increases in residential consumption are offsetting decreases in commercial consumption. It would be great to get access to this data!  Victorian electricity price profiles during Victoria\u0026rsquo;s stage 4 restrictions If you are like me and ask, \u0026ldquo;if residential electricity consumption has increased then will my electricity bill be through the roof?\u0026rdquo; The answer is it depends. The key variables are the electricity tariffs you pay (explore the Victorian energy compare website for more information) and the regional reference price (RRP) which reflects the price to supply electricity to a region.\n  Key takeaway messages from reviewing Victorian RRP data include:\n There has been a significant shift in RRP since last year. There is no longer a morning peak in RRP. There are currently less fluctuations in RRP throughout the day.  New South Wales electricity price profiles during Victoria\u0026rsquo;s stage 4 restrictions Again, we should compare this to New South Wales to see if the trend is specific to Victoria.\n  After reviewing the NSW RRP data, it is clear that the decline in RRP is not specific to Victoria.\nHow Australia\u0026rsquo;s Regional Reference Prices have changed over the years The next step is to compare the average RRP for electricity in each state for each year to the current date of analysis.\n  The key takeaway messages from reviewing state by state RRP include:\n RRP is at a 5-year low. Electricity RRP is heavily influenced by LNG which is in turn influenced by the price of oil. For the interested reader please refer here for more information. COVID-19 is not the only reason electricity prices are at 5 year low, there are a number of other important factors to consider.  Summary When compared to this time last year, weekend electricity consumption under the current restrictions is less regular for Victoria. COVID-19, among other factors, has driven the regional reference price for electricity to a 5-year low.\n2020 has been a year of uncertainty and the need for good quality forecasts has increased. Prior to making any predictions about the future it is imperative that the data is explored and key drivers for change are understood. Even then, unprecedented changes make forecasting even more difficult.\n","date":1601251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602979200,"objectID":"3ee91b2f9cc6d591edd0af6c2372e2b1","permalink":"https://AshjWright88.github.io/post/energy-consumption-pandemic-part-a/","publishdate":"2020-09-28T00:00:00Z","relpermalink":"/post/energy-consumption-pandemic-part-a/","section":"post","summary":"The COVID-19 pandemic has changed our understanding of uncertainty and what exactly normal is. We have seen economies free fall, toilet paper being hoarded, and unprecedented amounts of data made publicly available.","tags":null,"title":"Exploring Electricity Consumption Data","type":"post"},{"authors":null,"categories":null,"content":"Accurate flood predictions are critically important for limiting the damage caused by floods. Flood forecasting systems are based on models that require large volumes of data, such as rainfall forecasts, detailed measurements and high-resolution topography. However, flood forecasts are prone to uncertainty due to a lack of detailed measurements, and possible errors or oversimplifications in the models and/or data sets. Remote sensing is the science of obtaining information about objects or areas from a distance, typically from aircraft or satellites. This research is integrating this type of data on soil moisture and flood extent with rainfall and runoff models, which will lead to more accurate flood predictions. It will develop a remote sensing-aided methodology that can eventually enable forecasting models that predict the volume of water entering the river network to be applied anywhere in Australia.\n","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"f8f273020c3733f692087b48dfece9d8","permalink":"https://AshjWright88.github.io/project/floodforecasting/","publishdate":"2020-09-14T00:00:00Z","relpermalink":"/project/floodforecasting/","section":"project","summary":"Accurate flood predictions are critically important for limiting the damage caused by floods. This research integrates remote sening data into flood forecasting models.","tags":null,"title":"improving Flood Forecast Skill Using Remote Sensing Data","type":"project"},{"authors":null,"categories":null,"content":"","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"844ba629bc2ca310dac5364822c91bc9","permalink":"https://AshjWright88.github.io/project/leapfrogging/","publishdate":"2020-09-14T00:00:00Z","relpermalink":"/project/leapfrogging/","section":"project","summary":"This project developed a strategy for the Indonesian city of Greater Bogor to leapfrog to a more sustainable city.","tags":null,"title":"Leapfrogging strategy for Bogor Raya","type":"project"},{"authors":["Ashley J. Wright","Jeffrey P. Walker","Valentijn R.N. Pauwels"],"categories":[],"content":"","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600059379,"objectID":"d5ffb7e364c1bf995e8988508cb989a8","permalink":"https://AshjWright88.github.io/publication/wright-2018/","publishdate":"2020-09-14T04:56:18.976246Z","relpermalink":"/publication/wright-2018/","section":"publication","summary":"An increased understanding of the uncertainties present in rainfall time series can lead to improved confidence in both short- and long-term streamflow forecasts. This study presents an analysis that considers errors arising from model input data, model structure, model parameters, and model states with the objective of finding a self-consistent set that includes hydrological models, model parameters, streamflow, remotely sensed (RS) soil moisture (SM), and rainfall. This methodology can be used by hydrologists to aid model and satellite selection. Taking advantage of model input data reduction and model inversion techniques, this study uses a previously developed methodology to estimate areal rainfall time series for the study catchment of Warwick, Australia, for multiple rainfall-runoff models. RS SM observations from the Soil Moisture Ocean Salinity (SMOS) and Advanced Microwave Scanning Radiometer for Earth Observing System (AMSR-E) satellites were assimilated into three different rainfall-runoff models using an ensemble Kalman filter (EnKF). Innovations resulting from the observed and predicted SM were analyzed for Gaussianity. The findings demonstrate that consistency between hydrological models, model parameters, streamflow, RS SM, and rainfall can be found. Joint estimation of rainfall time series and model parameters consistently improved streamflow simulations. For all models rainfall estimates are less than the observed rainfall, and rainfall estimates obtained using the Sacramento Soil Moisture Accounting (SAC-SMA) model are the most consistent with gauge-based observations. The SAC-SMA model simulates streamflow that is most consistent with observations. EnKF innovations obtained when SMOS RS SM observations were assimilated into the SAC-SMA model demonstrate consistency between SM products.","tags":["\"Ensembles\"","\"Hydrologic models\"","\"Kalman filters\"","\"Model evaluation/performance\"","\"Optimization\""],"title":"Identification of hydrologic models, optimized parameters, and rainfall inputs consistent with in situ streamflow and rainfall and remotely sensed soil moisture","type":"publication"},{"authors":["Ashkan Shokri","Jeffrey P. Walker","Albert I. J. M. van Dijk","Ashley J. Wright","Valentijn R. N. Pauwels"],"categories":[],"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600059378,"objectID":"52d81a51153bbcb0fafadb7150bdf059","permalink":"https://AshjWright88.github.io/publication/shokri-2018/","publishdate":"2020-09-14T04:56:18.699987Z","relpermalink":"/publication/shokri-2018/","section":"publication","summary":"Finding an operational parameter vector is always challenging in the application of hydrologic models, with over-parameterization and limited information from observations leading to uncertainty about the best parameter vectors. Thus, it is beneficial to find every possible behavioural parameter vector. This paper presents a new methodology, called the patient rule induction method for parameter estimation (PRIM-PE), to define where the behavioural parameter vectors are located in the parameter space. The PRIM-PE was used to discover all regions of the parameter space containing an acceptable model behaviour. This algorithm consists of an initial sampling procedure to generate a parameter sample that sufficiently represents the response surface with a uniform distribution within the “good-enough” region (i.e., performance better than a predefined threshold) and a rule induction component (PRIM), which is then used to define regions in the parameter space in which the acceptable parameter vectors are located. To investigate its ability in different situations, the methodology is evaluated using four test problems. The PRIM-PE sampling procedure was also compared against a Markov chain Monte Carlo sampler known as the differential evolution adaptive Metropolis (DREAMZS) algorithm. Finally, a spatially distributed hydrological model calibration problem with two settings (a three-parameter calibration problem and a 23-parameter calibration problem) was solved using the PRIM-PE algorithm. The results show that the PRIM-PE method captured the good-enough region in the parameter space successfully using 8 and 107 boxes for the three-parameter and 23-parameter problems, respectively. This good-enough region can be used in a global sensitivity analysis to provide a broad range of parameter vectors that produce acceptable model performance. Moreover, for a specific objective function and model structure, the size of the boxes can be used as a measure of equifinality.","tags":["\"PRIM-PE\"","\"equifinality\"","\"hydrological model\"","\"parameter estimation\"","\"uncertainty quantification\""],"title":"Application of the patient rule induction method to detect hydrologic model behavioural parameters and quantify uncertainty","type":"publication"},{"authors":["Ashley J. Wright","Jeffrey P. Walker","Valentijn R. N. Pauwels"],"categories":[],"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600059378,"objectID":"ecfd09a9c52f96aada2d20660c605002","permalink":"https://AshjWright88.github.io/publication/wright-2017-a/","publishdate":"2020-09-14T04:56:18.418737Z","relpermalink":"/publication/wright-2017-a/","section":"publication","summary":"Floods are devastating natural hazards. To provide accurate, precise, and timely flood forecasts, there is a need to understand the uncertainties associated within an entire rainfall time series, even when rainfall was not observed. The estimation of an entire rainfall time series and model parameter distributions from streamflow observations in complex dynamic catchments adds skill to current areal rainfall estimation methods, allows for the uncertainty of entire rainfall input time series to be considered when estimating model parameters, and provides the ability to improve rainfall estimates from poorly gauged catchments. Current methods to estimate entire rainfall time series from streamflow records are unable to adequately invert complex nonlinear hydrologic systems. This study aims to explore the use of wavelets in the estimation of rainfall time series from streamflow records. Using the Discrete Wavelet Transform (DWT) to reduce rainfall dimensionality for the catchment of Warwick, Queensland, Australia, it is shown that model parameter distributions and an entire rainfall time series can be estimated. Including rainfall in the estimation process improves streamflow simulations by a factor of up to 1.78. This is achieved while estimating an entire rainfall time series, inclusive of days when none was observed. It is shown that the choice of wavelet can have a considerable impact on the robustness of the inversion. Combining the use of a likelihood function that considers rainfall and streamflow errors with the use of the DWT as a model data reduction technique allows the joint inference of hydrologic model parameters along with rainfall.","tags":["\"Bayesian statistics\"","\"parameter estimation\"","\"rainfall retrieval\"","\"wavelet transform\""],"title":"Estimating rainfall time series and model parameter distributions using model data reduction and inversion techniques","type":"publication"},{"authors":["Ashley Wright","Jeffrey P. Walker","David E. Robertson","Valentijn R.N. Pauwels"],"categories":[],"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600059378,"objectID":"9ff5b1b14dd0da80ac00ee3152a3aa45","permalink":"https://AshjWright88.github.io/publication/wright-2017/","publishdate":"2020-09-14T04:56:18.136745Z","relpermalink":"/publication/wright-2017/","section":"publication","summary":"The treatment of input data uncertainty in hydrologic models is of crucial importance in the analysis, diagnosis and detection of model structural errors. Data reduction techniques decrease the dimensionality of input data, thus allowing modern parameter estimation algorithms to more efficiently estimate errors associated with input uncertainty and model structure. The discrete cosine transform (DCT) and discrete wavelet transform (DWT) are used to reduce the dimensionality of observed rainfall time series for the 438 catchments in the Model Parameter Estimation Experiment (MOPEX) data set. The rainfall time signals are then reconstructed and compared to the observed hyetographs using standard simulation performance summary metrics and descriptive statistics. The results convincingly demonstrate that the DWT is superior to the DCT in preserving and characterizing the observed rainfall data records. It is recommended that the DWT be used for model input data reduction in hydrology in preference over the DCT.","tags":[],"title":"A comparison of the discrete cosine and wavelet transforms for hydrologic model input data reduction","type":"publication"}]